---
layout: post
title: "Machines Taught by Photos Learn a Sexist View of Women"
posturl: https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/
tags:
- Bias
- Image recognition
- Ethics
- Machine learning
---

{% include post_info_header.md %}

So sample datasets show more women in kitchen and men doing sports then vice versa. Machine learning algorithms learn it, and show us our existing biases. The more ML we use, the more we will see our biases in our data and everyday life - if we are carefully analyzing how ML systems behave. We realize the huge difference in the ideal world we are thinking about, and our real world, ML is data behaving. Here is the real question: how will this realization change our discussion around these biases? How will this change the discussions around biases in software development, in product development and design?

<!--more-->
{% include post_info_footer.md %}
