---
layout: post
title: Robust Physical-World Attacks on Machine Learning Models
posturl: https://arxiv.org/pdf/1707.08945v1.pdf
tags:
- Machine Learning
- Attacks
- Research
---

{% include post_info_header.md %}

It's interesting to see more and more research published on how to fool machine learning systems, vision based in particular. I can see designers on both sides, on one had as more and more ML tech is deployed to follow people without their informed consent there is a need for systems enabling users to hide. On the other hand systems designed should protect well-intentioned users from harm coming from attackers.

{% include post_info_footer.md %}
